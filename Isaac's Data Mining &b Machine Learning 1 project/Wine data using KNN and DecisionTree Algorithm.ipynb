{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b35d2a-1ce2-46f8-9d40-706ed7ca01d7",
   "metadata": {},
   "source": [
    "# 1. (A) KNN Implementation Using KNeighborsClassifier from the sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b80339-5648-464c-9960-82dd571aac87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.96\n",
      "F1 Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "# Combining of  features and target into a single DataFrame\n",
    "data = pd.DataFrame(X, columns=wine_data.feature_names)\n",
    "data['target'] = y\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Standardization of the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data.drop('target', axis=1))\n",
    "\n",
    "# Applying PCA to reduce dimensions to 5\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Save the preprocessed data including target\n",
    "preprocessed_data = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(5)])\n",
    "preprocessed_data['target'] = data['target']  # Ensure target is included after dropping duplicates\n",
    "preprocessed_data.to_csv('wine_knn_pca_data.csv', index=False)\n",
    "\n",
    "# Load the preprocessed data\n",
    "preprocessed_data = pd.read_csv('wine_knn_pca_data.csv')\n",
    "X = preprocessed_data.drop('target', axis=1)\n",
    "y = preprocessed_data['target']\n",
    "\n",
    "# Split the dataset into training and testing sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c29f1-acf1-49ce-a1d7-daef2f80ec4f",
   "metadata": {},
   "source": [
    "# 1B. KNN Implementation Using scipy KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82102faf-78f1-4cec-938b-9610af3c6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.96\n",
      "F1 Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import KDTree\n",
    "from collections import Counter\n",
    "\n",
    "# Load the preprocessed data\n",
    "preprocessed_data = pd.read_csv('wine_knn_pca_data.csv')\n",
    "X = preprocessed_data.drop('target', axis=1).values\n",
    "y = preprocessed_data['target'].values\n",
    "\n",
    "# Split the dataset into training and testing sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create KDTree with the training data\n",
    "tree = KDTree(X_train)\n",
    "\n",
    "# Query KDTree for k nearest neighbors (k=5)\n",
    "k = 5\n",
    "distances, indices = tree.query(X_test, k=k)\n",
    "\n",
    "# Aggregate predictions using majority voting\n",
    "predicted_labels = []\n",
    "for index_list in indices:\n",
    "    neighbor_labels = y_train[index_list]\n",
    "    most_common = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "    predicted_labels.append(most_common)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe610d-8c05-44a1-8895-31150659b026",
   "metadata": {},
   "source": [
    "# 2. (A) Implementation 1: Using DecisionTreeClassifier from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1118d03-a5a3-4c57-ad6c-0d3592a343d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " sklearn Decision Tree Classifier Results:\n",
      "F1 Score: 0.96\n",
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, classification_report, accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Series(wine.target, name='target')\n",
    "\n",
    "# Drop duplicates, if any\n",
    "X.drop_duplicates(inplace=True)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save preprocessed data to CSV\n",
    "preprocessed_data = pd.DataFrame(X_scaled, columns=wine.feature_names)\n",
    "preprocessed_data['target'] = y\n",
    "preprocessed_data.to_csv('preprocessed_wine_data.csv', index=False)\n",
    "\n",
    "# Load preprocessed data\n",
    "preprocessed_data = pd.read_csv('preprocessed_wine_data.csv')\n",
    "X = preprocessed_data.drop(columns=['target'])\n",
    "y = preprocessed_data['target']\n",
    "\n",
    "# Split data into training and testing sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# DecisionTreeClassifier Implementation\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "f1_clf = f1_score(y_test, y_pred_clf, average='weighted')\n",
    "accuracy_clf = accuracy_score(y_test, y_pred_clf)\n",
    "\n",
    "print(\"\\n sklearn Decision Tree Classifier Results:\")\n",
    "print(f\"F1 Score: {f1_clf:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_clf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5918b-6378-471d-9b7b-8133dd531861",
   "metadata": {},
   "source": [
    "# 2B. Implementation Using XGBOOST DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac0d994-ae00-4e07-8731-9c176f782170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classifier Results:\n",
      "F1 Score: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Load the preprocessed wine data from CSV\n",
    "preprocessed_data = pd.read_csv('preprocessed_wine_data.csv')\n",
    "X = preprocessed_data.drop(columns=['target'])\n",
    "y = preprocessed_data['target']\n",
    "\n",
    "# Split data into training and testing sets with the same 70/30 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the XGBoost classifier with consistent random state\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the same metrics\n",
    "f1_score_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(\"\\nXGBoost Classifier Results:\")\n",
    "print(f\"F1 Score: {f1_score_xgb:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb13ce8-ec2d-42ce-bbf1-bd58818574cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
