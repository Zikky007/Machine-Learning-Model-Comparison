{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7e8e66-b5a9-486e-a247-ad9a74170d58",
   "metadata": {},
   "source": [
    "# 1A. KNN Implementation Using KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de05c677-1c80-4b2f-b808-9453dc8418b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.55\n",
      "F1 Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Loading of dataset\n",
    "data = pd.read_csv('raw_heart_disease_dataset.csv')\n",
    "\n",
    "# Separate features and target\n",
    "features = data.drop('target', axis=1)\n",
    "target = data['target']\n",
    "\n",
    "# Encoding Categorical Variables\n",
    "for column in features.select_dtypes(include=['object']).columns:\n",
    "    features[column] = LabelEncoder().fit_transform(features[column])\n",
    "\n",
    "# Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Save and load the preprocessed data\n",
    "preprocessed_data = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "preprocessed_data['target'] = target\n",
    "preprocessed_data.to_csv('preprocessed_heart_disease_dataset.csv', index=False)\n",
    "\n",
    "preprocessed_data = pd.read_csv('preprocessed_heart_disease_dataset.csv')\n",
    "X = preprocessed_data.drop('target', axis=1)\n",
    "y = preprocessed_data['target']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the KNeighborsClassifier with Euclidean distance\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca43524-0414-46de-a638-3c46a7016e03",
   "metadata": {},
   "source": [
    "## 1B. KNN Implementation Using scipy KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8ed760-fa46-4752-a61d-35228077a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.58\n",
      "F1 Score: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from collections import Counter\n",
    "\n",
    "# Load the preprocessed data\n",
    "preprocessed_data = pd.read_csv('preprocessed_heart_disease_dataset.csv')\n",
    "X = preprocessed_data.drop('target', axis=1).values\n",
    "y = preprocessed_data['target'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create KDTree with the training data\n",
    "tree = KDTree(X_train)\n",
    "\n",
    "# Query KDTree for k nearest neighbors\n",
    "k = 5\n",
    "distances, indices = tree.query(X_test, k=k)\n",
    "\n",
    "# Aggregate  the predictions using majority voting\n",
    "predicted_labels = []\n",
    "for index_list in indices:\n",
    "    neighbor_labels = y_train[index_list]\n",
    "    # Use mode to determine the most common class among neighbors\n",
    "    most_common = Counter(neighbor_labels).most_common(1)[0][0]\n",
    "    predicted_labels.append(most_common)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75baf8d3-2149-4d61-9cc5-7ed83b0edbf6",
   "metadata": {},
   "source": [
    "## Implementation using Scikit-learn DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34c90f4-c121-4e71-8bcb-67a146bfb8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values detected. Handling missing values.\n",
      "Checking for unrealistic data entries.\n",
      "Duplicates removed: 0\n",
      "Identified 85 outliers.\n",
      "Accuracy: 0.75\n",
      "F1 Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Loading of the dataset\n",
    "data = pd.read_csv('raw_heart_disease_dataset.csv')\n",
    "\n",
    "# Data Cleaning\n",
    "# Convert '?' to NaN and drop rows with any NaN values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "if data.isna().any().any():\n",
    "    print(\"Missing values detected. Handling missing values.\")\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "# Validate data entries (check for impossible values)\n",
    "print(\"Checking for unrealistic data entries.\")\n",
    "out_of_bounds = (data['age'] < 25) | (data['age'] > 100) | \\\n",
    "                (data['trestbps'] < 50) | (data['trestbps'] > 200) | \\\n",
    "                (data['chol'] < 100) | (data['chol'] > 600)\n",
    "if out_of_bounds.any():\n",
    "    data = data[~out_of_bounds]\n",
    "    print(f\"Removed {out_of_bounds.sum()} rows with unrealistic entries.\")\n",
    "\n",
    "# Handle categorical data with LabelEncoder\n",
    "for column in ['ca', 'thal']:\n",
    "    if data[column].dtype == 'object' or data[column].isna().any():\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column].astype(str))\n",
    "\n",
    "# Remove duplicates\n",
    "initial_count = len(data)\n",
    "data.drop_duplicates(inplace=True)\n",
    "print(f\"Duplicates removed: {initial_count - len(data)}\")\n",
    "\n",
    "# Outlier Detection and Removal using IQR\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "print(f\"Identified {outliers.sum()} outliers.\")\n",
    "data = data[~outliers]\n",
    "\n",
    "# Feature Scaling or normalization\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# To Ensure that the target is an integer for classification\n",
    "data['target'] = data['target'].astype(int)\n",
    "\n",
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X = pca.fit_transform(data.drop('target', axis=1))\n",
    "y = data['target']\n",
    "\n",
    "# Save the fully preprocessed data\n",
    "data.to_csv('preprocessed2_heart_disease_dataset.csv', index=False)\n",
    "\n",
    "# Load the preprocessed data\n",
    "data = pd.read_csv('preprocessed2_heart_disease_dataset.csv')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialization and training of the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation of the model\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136a3dd-02fc-40eb-808e-28c25aa90597",
   "metadata": {},
   "source": [
    "## Implementation using XGBOOST DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a115396-807b-46e5-a1e3-75a1e6bf89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "F1 Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Loading the preprocessed data\n",
    "data = pd.read_csv('preprocessed2_heart_disease_dataset.csv')\n",
    "\n",
    "# Split data into testing & training datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialization and training of  the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation of the model\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87272aa-890a-4378-8793-27fff643a244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
